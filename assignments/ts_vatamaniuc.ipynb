{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BI_time_series_cv.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okAKB7JTewOk"
      },
      "source": [
        "# Bussines Inteligence Lecture #5: Time Series Analysis\n",
        "Data table is online and updates every day.\n",
        "\n",
        "For analysis was taken covid-19 data form Czech Republic about total and new death & cases.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhezIl7kiREJ"
      },
      "source": [
        "Firstly let's import all nedeed packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7ku9FMViNri"
      },
      "source": [
        "import math\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "#default plot settings\n",
        "sns.set(rc={'figure.figsize':(16, 9)})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOngYVHbiX6H"
      },
      "source": [
        "Here we will upload our data table and set the indexing to time, so that means we will recieve a time series table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EagST-FoErgf"
      },
      "source": [
        "#Covid table upload with newest data\n",
        "covid_table = pd.read_csv('https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv')\n",
        "#Indexing -> creating time series\n",
        "covid_table['date'] = pd.to_datetime(covid_table['date'])\n",
        "covid_table = covid_table.set_index('date')\n",
        "print(covid_table.index)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3lF0kwZinoH"
      },
      "source": [
        "Let's make specific table for data from Czech Republic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkKTC_oFKK4v"
      },
      "source": [
        "#Force table to Czech Republic\n",
        "covid_talble_cz = covid_table.loc[covid_table['location'] == 'Czech Republic']\n",
        "used_columns = ['total_cases','new_cases','total_deaths', 'new_deaths']\n",
        "covid_talble_cz = covid_talble_cz[used_columns]\n",
        "covid_talble_cz = covid_talble_cz.fillna(0)\n",
        "print(covid_talble_cz.head())\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz3_wdmJituD"
      },
      "source": [
        "Next secton is for data visualizing of our data via plots and bars"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6mKCzqKOCTV"
      },
      "source": [
        "#Total cases plot\n",
        "covid_talble_cz['total_cases'].plot(linewidth=0.5);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYlSsepNTWXA"
      },
      "source": [
        "#Other plots\n",
        "axes = covid_talble_cz[used_columns].plot(marker='.', linestyle='-', alpha=0.5, figsize=(11, 9), subplots=True)\n",
        "for ax in axes:\n",
        "    ax.set_ylabel('People')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh5b6E1RTjh3"
      },
      "source": [
        "#Mothly mean table\n",
        "covid_talble_cz_monthly_mean = covid_talble_cz[used_columns].resample('M').mean()\n",
        "print(covid_talble_cz_monthly_mean.head())\n",
        "\n",
        "#Monthly mean of new cases bar\n",
        "monthly_cases_plot = covid_talble_cz_monthly_mean['new_cases'].plot.bar()\n",
        "monthly_cases_plot.set_ylabel('People')\n",
        "monthly_cases_plot.set_ylim(0, 12000)\n",
        "monthly_cases_plot.set_title('Monthly mean of new cases')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZFUoOiSbCrx"
      },
      "source": [
        "#Monthly mean of new deaths bar\n",
        "monthly_deaths_plot = covid_talble_cz_monthly_mean['new_deaths'].plot.bar(color='orange')\n",
        "monthly_deaths_plot.set_ylabel('People')\n",
        "monthly_deaths_plot.set_ylim(0, 250)\n",
        "monthly_deaths_plot.set_title('Monthly mean of new deaths')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvkcGfBtjMEO"
      },
      "source": [
        "This section contains LSTM Recurent Neural Netwrok that will be used for forecasting monthly mean of new deaths and cases. This code is mostly copy-paste form [this tutorial](https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/). The data was separated to train and test data. Mostly it's separated on 70% and 30% respectively, but in our case we have completely different behavior at the start and in the end. Morover because lack of data our prediction is not as good as we would it like to be."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ri0BP3JZTRQ"
      },
      "source": [
        "#Monthly mean new cases & new dearhs forecast with LSTM Recurent Neural Network\n",
        "#https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n",
        "\n",
        "dataset_full = covid_talble_cz.loc['2020-1':'2020']\n",
        "#dataset = dataset_full[['new_cases']] \n",
        "dataset = dataset_full[['new_deaths']]\n",
        "dataset = dataset.values\n",
        "\n",
        "# normalize the dataset\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "dataset = scaler.fit_transform(dataset)\n",
        "\n",
        "# split into train and test sets\n",
        "train_size = int(len(dataset) * 0.70)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "print(len(train), len(test))\n",
        "\n",
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, look_back=1):\n",
        "\tdataX, dataY = [], []\n",
        "\tfor i in range(len(dataset)-look_back-1):\n",
        "\t\ta = dataset[i:(i+look_back), 0]\n",
        "\t\tdataX.append(a)\n",
        "\t\tdataY.append(dataset[i + look_back, 0])\n",
        "\treturn numpy.array(dataX), numpy.array(dataY)\n",
        " \n",
        "# reshape into X=t and Y=t+1\n",
        "look_back = 1\n",
        "trainX, trainY = create_dataset(train, look_back)\n",
        "testX, testY = create_dataset(test, look_back)\n",
        "\n",
        "# reshape input to be [samples, time steps, features]\n",
        "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
        "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
        "\n",
        "# reshape input to be [samples, time steps, features]\n",
        "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
        "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
        "\n",
        "# create and fit the LSTM network\n",
        "model = Sequential()\n",
        "model.add(LSTM(4, input_shape=(1, look_back)))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(trainX, trainY, epochs=20, batch_size=1, verbose=2)\n",
        "\n",
        "# make predictions\n",
        "trainPredict = model.predict(trainX)\n",
        "testPredict = model.predict(testX)\n",
        "\n",
        "# invert predictions\n",
        "trainPredict = scaler.inverse_transform(trainPredict)\n",
        "trainY = scaler.inverse_transform([trainY])\n",
        "testPredict = scaler.inverse_transform(testPredict)\n",
        "testY = scaler.inverse_transform([testY])\n",
        "\n",
        "# shift train predictions for plotting\n",
        "trainPredictPlot = numpy.empty_like(dataset)\n",
        "trainPredictPlot[:, :] = numpy.nan\n",
        "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = numpy.empty_like(dataset)\n",
        "testPredictPlot[:, :] = numpy.nan\n",
        "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
        "# plot baseline and predictions\n",
        "plt.plot(scaler.inverse_transform(dataset))\n",
        "plt.plot(trainPredictPlot)\n",
        "plt.plot(testPredictPlot)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}